{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "#  Library\n",
    "# ===================================================================\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import math\n",
    "import time\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "import unicodedata\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "#  CFG\n",
    "# ===================================================================\n",
    "class CFG:\n",
    "    filename = \"exp011\"\n",
    "    seed = 42\n",
    "    n_splits = 5\n",
    "    data_dir = \"G:/マイドライブ/signate_StudentCup2023/data/\"\n",
    "    year_bins = 20\n",
    "    num_boost_round = 10000\n",
    "    stopping_rounds = 1500\n",
    "    n_trials = 300\n",
    "    save_dir = \"G:/マイドライブ/signate_StudentCup2023/exp/\"\n",
    "    num_cores = 4 # kaggleの方と統一\n",
    "    categorical_features = [\n",
    "        \"fuel\", \"title_status\", \"type\", \"state\", \"region\", \"manufacturer\", \"condition\", \"cylinders\", \"transmission\", \"drive\", \"size\", \"paint_color\"\n",
    "        ]\n",
    "    use_features = [\"odometer\", \"year\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "#  Utils\n",
    "# ===================================================================\n",
    "def seed_everything(seed):\n",
    "    \"\"\"fix random factors\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "seed_everything(CFG.seed)\n",
    "    \n",
    "\n",
    "def get_score(y_true, y_pred):\n",
    "    \"\"\"get MAPE score\"\"\"\n",
    "    score = mean_absolute_percentage_error(y_true, y_pred)\n",
    "    return score * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "#  Data Loading\n",
    "# ===================================================================\n",
    "train = pd.read_csv(CFG.data_dir+\"train.csv\")\n",
    "test = pd.read_csv(CFG.data_dir+\"test.csv\")\n",
    "\n",
    "region_coor = pd.read_csv(CFG.data_dir+\"region_coordinate.csv\")\n",
    "state_coor = pd.read_csv(CFG.data_dir+\"state_coordinate.csv\")\n",
    "\n",
    "train[\"flag\"] = \"train\"\n",
    "test[\"flag\"] = \"test\"\n",
    "all_data = pd.concat([train, test], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "#  feature_engineering\n",
    "# ===================================================================\n",
    "def preprocessing(all_data: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    train, testデータで共通の前処理のコード\n",
    "    \n",
    "    ・yearの異常値を直す\n",
    "    ・manufacturerの表記を統一する\n",
    "    ・sizeの表記を統一する\n",
    "    ・regionの欠損値をtrain dataの(state, region)の組み合わせから補完する。残った欠損値は調べて補完する。\n",
    "    ・title_statusとtypeの欠損値処理はとりあえず放置\n",
    "\n",
    "    Args:\n",
    "        all_data (pd.DataFrame): pd.concat([train, test], ignore_index=True)\n",
    "    \"\"\"\n",
    "    # year\n",
    "    year_dict = {\n",
    "        2999:1999,\n",
    "        3008:2008,\n",
    "        3011:2011,\n",
    "        3015:2015,\n",
    "        3017:2017,\n",
    "        3019:2019,\n",
    "    }\n",
    "    all_data[\"year\"] = all_data[\"year\"].replace(year_dict)\n",
    "    \n",
    "    \n",
    "    # manufacturer\n",
    "    all_data[\"manufacturer\"] = all_data[\"manufacturer\"].str.lower().apply(lambda x: unicodedata.normalize('NFKC', x))\n",
    "    manufacturer_map = {\n",
    "        'niѕsan':'nissan',\n",
    "        'nisѕan':'nissan',\n",
    "        'subαru':'subaru',\n",
    "        'toyotа':'toyota',\n",
    "        'sαturn':'saturn',\n",
    "        'аcura':'acura',\n",
    "        'vоlkswagen':'volkswagen',\n",
    "        'lexuѕ':'lexus',\n",
    "        'ᴄhrysler':'chrysler',\n",
    "    }\n",
    "    all_data[\"manufacturer\"] = all_data[\"manufacturer\"].replace(manufacturer_map)\n",
    "    \n",
    "    \n",
    "    # size\n",
    "    size_dict = {\n",
    "        \"fullーsize\":\"full-size\",\n",
    "        \"midーsize\":\"mid-size\",\n",
    "        \"subーcompact\":\"sub-compact\",\n",
    "        \"full−size\":\"full-size\",\n",
    "        \"mid−size\":\"mid-size\"\n",
    "    }\n",
    "    all_data[\"size\"] = all_data[\"size\"].replace(size_dict)\n",
    "        \n",
    "    \n",
    "    # 地域\n",
    "    ## region -> stateが一意に定まることを確認\n",
    "    region_state = {region:{} for region in all_data[all_data[\"flag\"]==\"train\"]['region'].unique()}\n",
    "    for row, value in all_data[all_data[\"flag\"]==\"train\"].iterrows():\n",
    "        if not pd.isna(value['state']):\n",
    "            if value['state'] not in region_state[value['region']]:\n",
    "                region_state[value['region']][value['state']] = 1\n",
    "            else:\n",
    "                region_state[value['region']][value['state']] += 1\n",
    "    for region, state_dict in region_state.items():\n",
    "        if len(state_dict) > 1 or state_dict == {}:\n",
    "            region_state[region] = pd.NA\n",
    "        else:\n",
    "            region_state[region] = list(state_dict.keys())[0]\n",
    "\n",
    "    ## regionからstateを決定\n",
    "    all_data['state'] = [region_state[region] if pd.isna(state) else state for region, state in zip(all_data['region'], all_data['state'])]\n",
    "    all_data.loc[all_data[\"region\"] == \"northwest KS\", \"state\"] = \"ks\"\n",
    "    all_data.loc[all_data[\"region\"] == \"ashtabula\", \"state\"] = \"oh\"\n",
    "    all_data.loc[all_data[\"region\"] == \"southern WV\", \"state\"] = \"wv\"\n",
    "    \n",
    "    all_data = pd.merge(all_data, region_coor, on=\"region\", how=\"left\")\n",
    "    all_data = pd.merge(all_data, state_coor, on=\"state\", how=\"left\")\n",
    "    \n",
    "    \n",
    "    # type\n",
    "    ## 欠損値 train: 456, test: 229\n",
    "    \n",
    "    # title_status\n",
    "    ## 欠損値 train: 456, test: 229\n",
    "    \n",
    "    # fuel\n",
    "    ## 欠損値 train: 1239, test: 1495\n",
    "    \n",
    "    \n",
    "    all_data[\"elapsed_years\"] = 2023 - all_data[\"year\"]\n",
    "    all_data[\"log_elapsed_years\"] = np.log(all_data[\"elapsed_years\"])\n",
    "    all_data[\"sqrt_elapsed_years\"] = np.sqrt(all_data[\"elapsed_years\"])\n",
    "    \n",
    "    return all_data\n",
    "\n",
    "all_data = preprocessing(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The variance of the mean of the folds:  4.695908800203918\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "#  Cross Validation\n",
    "# ===================================================================\n",
    "train = all_data[all_data[\"flag\"] == \"train\"].reset_index(drop=True)\n",
    "test = all_data[all_data[\"flag\"] == \"test\"].reset_index(drop=True)\n",
    "\n",
    "train.sort_values(by=\"id\", ignore_index=True, inplace=True)\n",
    "\n",
    "# priceを小さい順に各foldに振り分ける\n",
    "train.sort_values(by=\"price\", ignore_index=True, inplace=True)\n",
    "train[\"fold\"] = [i for i in range(CFG.n_splits)] * (train.shape[0] // CFG.n_splits) + [i for i in range(train.shape[0] % CFG.n_splits)]\n",
    "train.sort_values(by=\"id\", ignore_index=True, inplace=True)\n",
    "print(\"The variance of the mean of the folds: \", train.groupby(\"fold\")[\"price\"].mean().std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_per_fold(CFG, train:pd.DataFrame, test: pd.DataFrame,  fold: int = 0):\n",
    "    \"\"\"foldごとの前処理: leakageを防ぐ\n",
    "\n",
    "    Args:\n",
    "        CFG :config\n",
    "        train (pd.DataFrame): 学習データ\n",
    "        test (pd.DataFrame, optional): test data Defaults to None.\n",
    "        fold (int, optional): Defaults to 0.\n",
    "        predict (bool, optional): 予測するか否か. Defaults to False.\n",
    "    \"\"\"\n",
    "    X_train = train[train[\"fold\"] != fold].reset_index(drop=True)\n",
    "    X_valid = train[train[\"fold\"] == fold].reset_index(drop=True)    \n",
    "    test_df = test.copy()\n",
    "\n",
    "    # odometerの補正\n",
    "    ## odometerが100以下or400000以上を異常値と考えて補完する\n",
    "    ## year_mapがodometerの分散が大きくなる特徴量だったのでこれを利用してodometerを補完する\n",
    "    fillna_map = X_train[(X_train[\"odometer\"] > 100)&(X_train[\"odometer\"] < 400000)].groupby([\"region\"])[\"odometer\"].mean().reset_index()\n",
    "    \n",
    "    def replace_odometer(df: pd.DataFrame, fillna_map: pd.DataFrame)-> pd.DataFrame:\n",
    "        \"\"\"odometerの異常値をfillna_mapを利用して補完する\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): 補完前のデータ\n",
    "            fillna_map (pd.DataFrame): 補完するデータ\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: 補完後のデータ\n",
    "        \"\"\"\n",
    "        df_1 = df[(df[\"odometer\"] < 100)|(df[\"odometer\"] > 400000)].reset_index(drop=True)\n",
    "        df_2 = df[(df[\"odometer\"] >= 100)&(df[\"odometer\"] <= 400000)].reset_index(drop=True)\n",
    "        df_1.drop(\"odometer\", inplace=True, axis=1)\n",
    "        df_1 = pd.merge(df_1, fillna_map, on=\"region\", how=\"left\")\n",
    "        df = pd.concat([df_1, df_2])\n",
    "        return df.sort_values(\"id\", ignore_index=True)\n",
    "    \n",
    "    \n",
    "    X_train = replace_odometer(X_train, fillna_map)\n",
    "    X_valid = replace_odometer(X_valid, fillna_map)\n",
    "    test_df = replace_odometer(test_df, fillna_map)\n",
    "    X_train[\"odometer\"].fillna(X_train[\"odometer\"].mean(), inplace=True)\n",
    "    X_valid[\"odometer\"].fillna(X_train[\"odometer\"].mean(), inplace=True)\n",
    "    test_df[\"odometer\"].fillna(test_df[\"odometer\"].mean(), inplace=True)\n",
    "        \n",
    "\n",
    "    # 交互作用\n",
    "    def apply_fe(df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"foldごとの特徴量作成\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame)\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: 特徴量作成後のdf\n",
    "        \"\"\"\n",
    "        df[\"log_odometer\"] = np.log(df[\"odometer\"])\n",
    "        df[\"sqrt_odometer\"] = np.sqrt(df[\"odometer\"])\n",
    "        \n",
    "        df[\"elapsed_years*odometer\"] = df[\"elapsed_years\"] * df[\"odometer\"]\n",
    "        df[\"elapsed_years*log_odometer\"] = df[\"elapsed_years\"] * df[\"log_odometer\"]\n",
    "        df[\"elapsed_years*sqrt_odometer\"] = df[\"elapsed_years\"] * df[\"sqrt_odometer\"]\n",
    "        \n",
    "        df[\"log_elapsed_years*odometer\"] = df[\"log_elapsed_years\"] * df[\"odometer\"]\n",
    "        df[\"log_elapsed_years*log_odometer\"] = df[\"log_elapsed_years\"] * df[\"log_odometer\"]\n",
    "        df[\"log_elapsed_years*sqrt_odometer\"] = df[\"log_elapsed_years\"] * df[\"sqrt_odometer\"]\n",
    "        \n",
    "        df[\"sqrt_elapsed_years*odometer\"] = df[\"sqrt_elapsed_years\"] * df[\"odometer\"]\n",
    "        df[\"sqrt_elapsed_years*log_odometer\"] = df[\"sqrt_elapsed_years\"] * df[\"log_odometer\"]\n",
    "        df[\"sqrt_elapsed_years*sqrt_odometer\"] = df[\"sqrt_elapsed_years\"] * df[\"sqrt_odometer\"]\n",
    "        return df\n",
    "    X_train = apply_fe(X_train)\n",
    "    X_valid = apply_fe(X_valid)\n",
    "    test_df = apply_fe(test_df)\n",
    "        \n",
    "        \n",
    "    # カウントエンコーディング\n",
    "    for col in CFG.categorical_features:\n",
    "        count_map = X_train[col].value_counts().to_dict()\n",
    "        X_train[col+\"_count_encoding\"] = X_train[col].map(count_map)\n",
    "        X_valid[col+\"_count_encoding\"] = X_valid[col].map(count_map)\n",
    "        test_df[col+\"_count_encoding\"] = test_df[col].map(count_map)\n",
    "        #if fold == 0:\n",
    "        #    CFG.candidates.append(col+\"_count_encoding\")\n",
    "        \n",
    "        \n",
    "    # 集約特徴量を用いたエンコーディング\n",
    "    for col in CFG.categorical_features:\n",
    "        for agg_ in [\"mean\", \"std\", \"max\", \"min\", \"median\"]:\n",
    "            fillna_map = X_train.groupby(col)[\"price\"].agg(agg_)\n",
    "            X_train[col+f\"_{agg_}_encoding\"] = X_train[col].map(fillna_map)\n",
    "            X_valid[col+f\"_{agg_}_encoding\"] = X_valid[col].map(fillna_map)\n",
    "            test_df[col+f\"_{agg_}_encoding\"] = test_df[col].map(fillna_map)\n",
    "            #if fold == 0:\n",
    "            #    CFG.candidates.append(col+f\"_{agg_}_encoding\")\n",
    "                \n",
    "    # 集約特徴量を用いたエンコーディング\n",
    "    for col in CFG.categorical_features:\n",
    "        for agg_ in [\"mean\", \"std\", \"max\", \"min\", \"median\"]:\n",
    "            fillna_map = X_train.groupby(col)[\"odometer\"].agg(agg_)\n",
    "            X_train[col+f\"_{agg_}_odometer_encoding\"] = X_train[col].map(fillna_map)\n",
    "            X_valid[col+f\"_{agg_}_odometer_encoding\"] = X_valid[col].map(fillna_map)\n",
    "            test_df[col+f\"_{agg_}_odometer_encoding\"] = test_df[col].map(fillna_map)\n",
    "            #if fold == 0:\n",
    "            #    CFG.candidates.append(col+f\"_{agg_}_odometer_encoding\")\n",
    "            if agg_ == \"median\" or agg_ == \"mean\":\n",
    "                X_train[col+f\"_{agg_}_odometer_encoding_diff\"] = X_train[col+f\"_{agg_}_odometer_encoding\"] - X_train[\"odometer\"]\n",
    "                X_valid[col+f\"_{agg_}_odometer_encoding_diff\"] = X_valid[col+f\"_{agg_}_odometer_encoding\"] - X_valid[\"odometer\"]\n",
    "                test_df[col+f\"_{agg_}_odometer_encoding_diff\"] = test_df[col+f\"_{agg_}_odometer_encoding\"] - test_df[\"odometer\"]\n",
    "                #if fold == 0:\n",
    "                #    CFG.candidates.append(col+f\"_{agg_}_odometer_encoding_diff\")\n",
    "                    \n",
    "                    \n",
    "    # 集約特徴量を用いたエンコーディング\n",
    "    for col in CFG.categorical_features:\n",
    "        for agg_ in [\"mean\", \"std\", \"max\", \"min\", \"median\"]:\n",
    "            fillna_map = X_train.groupby(col)[\"elapsed_years\"].agg(agg_)\n",
    "            X_train[col+f\"_{agg_}_elapsed_years_encoding\"] = X_train[col].map(fillna_map)\n",
    "            X_valid[col+f\"_{agg_}_elapsed_years_encoding\"] = X_valid[col].map(fillna_map)\n",
    "            test_df[col+f\"_{agg_}_elapsed_years_encoding\"] = test_df[col].map(fillna_map)\n",
    "            #if fold == 0:\n",
    "            #    CFG.candidates.append(col+f\"_{agg_}_elapsed_years_encoding\")\n",
    "            if agg_ == \"median\" or agg_ == \"mean\":\n",
    "                X_train[col+f\"_{agg_}_elapsed_years_encoding_diff\"] = X_train[col+f\"_{agg_}_elapsed_years_encoding\"] - X_train[\"elapsed_years\"]\n",
    "                X_valid[col+f\"_{agg_}_elapsed_years_encoding_diff\"] = X_valid[col+f\"_{agg_}_elapsed_years_encoding\"] - X_valid[\"elapsed_years\"]\n",
    "                test_df[col+f\"_{agg_}_elapsed_years_encoding_diff\"] = test_df[col+f\"_{agg_}_elapsed_years_encoding\"] - test_df[\"elapsed_years\"]\n",
    "\n",
    "                #if fold == 0:\n",
    "                #    CFG.candidates.append(col+f\"_{agg_}_elapsed_years_encoding_diff\")\n",
    "\n",
    "                \n",
    "    \"\"\"\n",
    "    # target encodingしたやつらの交互作用\n",
    "    te = [col for col in X_train.columns if \"_mean_\" in col and \"_diff\" not in col] \n",
    "    for i, col1 in enumerate(tqdm(te)):\n",
    "        for col2 in te[i:]:\n",
    "            X_train[f\"{col1}*{col2}\"] = X_train[col1] * X_train[col2]\n",
    "            X_valid[f\"{col1}*{col2}\"] = X_valid[col1] * X_valid[col2]\n",
    "            if fold == 0:\n",
    "                CFG.candidates.append(f\"{col1}*{col2}\")\n",
    "    \"\"\"\n",
    "\n",
    "            \n",
    "    # OrdinalEncoder: これはfoldごとではなくともよい\n",
    "    oe = OrdinalEncoder(categories=\"auto\",\n",
    "                        handle_unknown=\"use_encoded_value\",\n",
    "                        unknown_value=999,\n",
    "                        encoded_missing_value=np.nan, # QUESTION: 欠損値は-1に変換する -> NaNに??\n",
    "                        )\n",
    "    CFG.categorical_features_ = [feature + \"_category\" for feature in CFG.categorical_features]\n",
    "    X_train[CFG.categorical_features_] = oe.fit_transform(X_train[CFG.categorical_features].values)\n",
    "    X_valid[CFG.categorical_features_] = oe.transform(X_valid[CFG.categorical_features].values)\n",
    "    test_df[CFG.categorical_features_] = oe.transform(test_df[CFG.categorical_features].values)\n",
    "    return X_train, X_valid, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "#  preprocessing_per_fold\n",
    "# ===================================================================\n",
    "X_train0, X_valid0, test_df0 = preprocessing_per_fold(CFG, train, test, 0)\n",
    "X_train1, X_valid1, test_df1 = preprocessing_per_fold(CFG, train, test, 1)\n",
    "X_train2, X_valid2, test_df2 = preprocessing_per_fold(CFG, train, test, 2)\n",
    "X_train3, X_valid3, test_df3 = preprocessing_per_fold(CFG, train, test, 3)\n",
    "X_train4, X_valid4, test_df4 = preprocessing_per_fold(CFG, train, test, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "#  evaluate\n",
    "# ===================================================================\n",
    "def train_lgb(CFG, lgb_param):\n",
    "    oof_df = pd.DataFrame()\n",
    "    for fold, (X_train, X_valid) in enumerate(zip([X_train0, X_train1, X_train2, X_train3, X_train4], [X_valid0, X_valid1, X_valid2, X_valid3, X_valid4])):\n",
    "        # train\n",
    "        categorical_features = [col for col in CFG.use_features if \"_category\" in col]\n",
    "        lgb_train = lgb.Dataset(X_train[CFG.use_features], X_train[\"price\"], categorical_feature = categorical_features,)\n",
    "        lgb_valid = lgb.Dataset(X_valid[CFG.use_features], X_valid[\"price\"], categorical_feature = categorical_features,)\n",
    "        model = lgb.train(\n",
    "                        lgb_param, \n",
    "                        lgb_train, \n",
    "                        valid_sets=[lgb_valid],\n",
    "                        categorical_feature = categorical_features,\n",
    "                        callbacks=[lgb.early_stopping(stopping_rounds=CFG.stopping_rounds, verbose=False),],\n",
    "                        )\n",
    "\n",
    "        X_valid[f\"pred\"] = model.predict(X_valid[CFG.use_features], num_iteration=model.best_iteration)\n",
    "        print(f\"fold{fold}:\", get_score(y_true=X_valid[\"price\"], y_pred=X_valid[\"pred\"]))\n",
    "        oof_df = pd.concat([oof_df, X_valid], ignore_index=True)\n",
    "\n",
    "    score = get_score(oof_df[\"price\"], oof_df[\"pred\"])\n",
    "    return score\n",
    "\n",
    "\n",
    "def predict_lgb(CFG, lgb_param):\n",
    "    oof_df = pd.DataFrame()\n",
    "    preds = []\n",
    "    for fold, (X_train, X_valid, test_df) in enumerate(zip([X_train0, X_train1, X_train2, X_train3, X_train4], [X_valid0, X_valid1, X_valid2, X_valid3, X_valid4], \n",
    "                                                           [test_df0, test_df1, test_df2, test_df3, test_df4])):\n",
    "        # train\n",
    "        categorical_features = [col for col in CFG.use_features if \"_category\" in col]\n",
    "        lgb_train = lgb.Dataset(X_train[CFG.use_features], X_train[\"price\"], categorical_feature = categorical_features,)\n",
    "        lgb_valid = lgb.Dataset(X_valid[CFG.use_features], X_valid[\"price\"], categorical_feature = categorical_features,)\n",
    "        model = lgb.train(\n",
    "                        lgb_param, \n",
    "                        lgb_train, \n",
    "                        valid_sets=[lgb_valid],\n",
    "                        categorical_feature = categorical_features,\n",
    "                        callbacks=[lgb.early_stopping(stopping_rounds=CFG.stopping_rounds, verbose=False),],\n",
    "                        )\n",
    "\n",
    "        X_valid[f\"pred\"] = model.predict(X_valid[CFG.use_features], num_iteration=model.best_iteration)\n",
    "        print(f\"fold{fold}:\", get_score(y_true=X_valid[\"price\"], y_pred=X_valid[\"pred\"]))\n",
    "        oof_df = pd.concat([oof_df, X_valid], ignore_index=True)\n",
    "        preds.append(model.predict(test_df[CFG.use_features]))\n",
    "    test[f\"pred\"] = np.mean(preds, axis=0)        \n",
    "    score = get_score(oof_df[\"price\"], oof_df[\"pred\"])\n",
    "    return score, oof_df, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG.use_features = [\n",
    "    'year', 'odometer', \n",
    "    \"fuel_std_elapsed_years_encoding\", \n",
    "    \"type_median_encoding\",\n",
    "    \"fuel_median_odometer_encoding_diff\",\n",
    "    \"drive_median_odometer_encoding\",\n",
    "    \"type_median_odometer_encoding\", \n",
    "    \"size_min_odometer_encoding\",\n",
    "    \"size_category\",\n",
    "    \"condition_median_odometer_encoding\", \n",
    "    \"drive_mean_elapsed_years_encoding_diff\",\n",
    "    \"manufacturer_std_encoding\",\n",
    "    \"condition_category\",\n",
    "    \"paint_color_mean_elapsed_years_encoding\", \n",
    "    \"drive_category\", \n",
    "    \"size_min_encoding\",\n",
    "    \"title_status_max_odometer_encoding\",\n",
    "    \"drive_std_encoding\", \n",
    "    \"paint_color_std_encoding\",\n",
    "    \"cylinders_mean_odometer_encoding\", \n",
    "    \"title_status_max_elapsed_years_encoding\", \n",
    "    \"title_status_min_odometer_encoding\",\n",
    "    \"title_status_mean_encoding\", \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold0: 43.71319223648226\n",
      "fold1: 43.95802175104515\n",
      "fold2: 43.902310683957516\n",
      "fold3: 44.602986661882106\n",
      "fold4: 44.6082949282621\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "44.15693790827101"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_param = {\n",
    "    \"task\":\"train\",\n",
    "    \"objective\": \"mape\",\n",
    "    \"boosting\":\"gbdt\",\n",
    "    \"num_iterations\": CFG.num_boost_round,\n",
    "    \"learning_rate\": 0.1, # default: 0.1\n",
    "    \"min_child_weight\":1e-3, # double: minimal sum hessian in one leaf\n",
    "    \"subsample\":1, #0.0 < bagging_fraction <= 1.0\n",
    "    \"num_threads\":CFG.num_cores,\n",
    "    \"metric\": 'mape',\n",
    "    \"seed\" : CFG.seed,\n",
    "    \"verbosity\": -1,   \n",
    "    \"max_depth\": 9,\n",
    "    \"num_leaves\": 111, # < 2**\"max_depth\"\n",
    "    \"alpha\": 6.55318242691208,\n",
    "    \"lambda\": 0.5433605593255564,\n",
    "    \"colsample_bytree\":0.14763728104095547,\n",
    "    \"min_child_samples\": 91, \n",
    "    \"feature_fraction\": 0.41970023278727786, \n",
    "    \"bagging_fraction\": 0.9529988287766262, \n",
    "    \"bagging_freq\": 4\n",
    "}    \n",
    "\n",
    "best_score, oof_df, test_df = predict_lgb(CFG, lgb_param)\n",
    "best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>region</th>\n",
       "      <th>year</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>condition</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>fuel</th>\n",
       "      <th>title_status</th>\n",
       "      <th>transmission</th>\n",
       "      <th>drive</th>\n",
       "      <th>...</th>\n",
       "      <th>state_category</th>\n",
       "      <th>region_category</th>\n",
       "      <th>manufacturer_category</th>\n",
       "      <th>condition_category</th>\n",
       "      <th>cylinders_category</th>\n",
       "      <th>transmission_category</th>\n",
       "      <th>drive_category</th>\n",
       "      <th>size_category</th>\n",
       "      <th>paint_color_category</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>nashville</td>\n",
       "      <td>1949</td>\n",
       "      <td>bmw</td>\n",
       "      <td>excellent</td>\n",
       "      <td>6 cylinders</td>\n",
       "      <td>gas</td>\n",
       "      <td>clean</td>\n",
       "      <td>manual</td>\n",
       "      <td>rwd</td>\n",
       "      <td>...</td>\n",
       "      <td>42.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7852.022130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>wichita</td>\n",
       "      <td>1998</td>\n",
       "      <td>ford</td>\n",
       "      <td>good</td>\n",
       "      <td>6 cylinders</td>\n",
       "      <td>gas</td>\n",
       "      <td>clean</td>\n",
       "      <td>automatic</td>\n",
       "      <td>fwd</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>356.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3588.764971</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 289 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id     region  year manufacturer  condition    cylinders fuel title_status  \\\n",
       "0   0  nashville  1949          bmw  excellent  6 cylinders  gas        clean   \n",
       "1   2    wichita  1998         ford       good  6 cylinders  gas        clean   \n",
       "\n",
       "  transmission drive  ... state_category region_category  \\\n",
       "0       manual   rwd  ...           42.0           214.0   \n",
       "1    automatic   fwd  ...           16.0           356.0   \n",
       "\n",
       "  manufacturer_category condition_category  cylinders_category  \\\n",
       "0                   4.0                0.0                 5.0   \n",
       "1                  11.0                2.0                 5.0   \n",
       "\n",
       "  transmission_category  drive_category  size_category  paint_color_category  \\\n",
       "0                   1.0             2.0            2.0                   6.0   \n",
       "1                   0.0             1.0            1.0                   9.0   \n",
       "\n",
       "          pred  \n",
       "0  7852.022130  \n",
       "1  3588.764971  \n",
       "\n",
       "[2 rows x 289 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof_df.to_csv(CFG.save_dir+f\"{CFG.filename}_oof_df.csv\", index=False)\n",
    "oof_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27532</td>\n",
       "      <td>9555.709628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27533</td>\n",
       "      <td>5404.466001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27534</td>\n",
       "      <td>5689.281097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27535</td>\n",
       "      <td>17927.816071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27536</td>\n",
       "      <td>4083.102189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27532</th>\n",
       "      <td>55064</td>\n",
       "      <td>13244.058557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27533</th>\n",
       "      <td>55065</td>\n",
       "      <td>8422.142162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27534</th>\n",
       "      <td>55066</td>\n",
       "      <td>5837.442376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27535</th>\n",
       "      <td>55067</td>\n",
       "      <td>5532.013469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27536</th>\n",
       "      <td>55068</td>\n",
       "      <td>5275.898735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27537 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id          pred\n",
       "0      27532   9555.709628\n",
       "1      27533   5404.466001\n",
       "2      27534   5689.281097\n",
       "3      27535  17927.816071\n",
       "4      27536   4083.102189\n",
       "...      ...           ...\n",
       "27532  55064  13244.058557\n",
       "27533  55065   8422.142162\n",
       "27534  55066   5837.442376\n",
       "27535  55067   5532.013469\n",
       "27536  55068   5275.898735\n",
       "\n",
       "[27537 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[[\"id\", \"pred\"]].to_csv(CFG.save_dir+f\"{CFG.filename}.csv\", index=False, header=None)\n",
    "test_df[[\"id\", \"pred\"]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
